{
  "cells": [
    {
      "cell_type": "raw",
      "id": "4382a2df",
      "metadata": {},
      "source": [
        "---\n",
        "title: Methods\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd6a2211",
      "metadata": {},
      "source": [
        "The first method that will be implemented is a decision tree for classification. A decision tree is a form of supervised learning in which the machine 'learns' a series of sequential rules by which the data can be broken down. Decision trees recursivley partitions the dataset based on the features of the dataset. The result is a 'tree', where the top represents the whole dataset. From there, the features are analyzed and rules are inferrred at each level. Once a rule is inferred, a new branch is created. The branches become more granular as the algorithm traverses down the tree. Then, the tree is pruned in order to simplify the algorithm and remove nodes that to not contribute to the classifying power of the algorithm. For classification, the rules are inferred which can then be used to predict class label. These trees are a type of predictive workflow, such that a new data point can be predictively classified based on the extent to which they meet conditions at each node within the decision tree.\n",
        "\n",
        "Decision trees can also be used for regression. The structure of the decision tree is exactly as described as above - a series of connected nodes based on inferred rules from a labeled dataset. However, instead of predicting class, the tree can be used to infer numerical values based on some input. It is similar to plugging in a speculative x value in a y=mx+b equation to predidct y. However, the input will traverse along the edges of the tree and a numerical prediction will be made at each note. The output is predicted based on the final node that the input reaches on the tree. \n",
        "\n",
        "Random Forests will also be used in this analysis. A random forrest is a collection of decision trees. The algorithm generates many decision trees and aggregates their outputs to generate a more robust predicition either for regression or classification tasks. The random forest is a more robust machine learning algorithm when compared to the decision tree. Decision trees are vulnerable to overfitting, a weakness that is subverted through the implementation of a random forest. However, they are more computationally expensive. Random forrests can be used for classification or regression - the former combines many decision trees for classification and the latter combines many decision trees for regression. Once the results are aggregated, some measure of center is taken to generate the output. \n",
        "\n",
        "This analysis aims to leverage decision trees and random forrests to develop models to predict human freedom and political regime. Human freedom is measured as the human freedom score, as is defined by the Cato Institute. Regression modeling will be used to develop predictive models for freedom based off of economic, political, educational, and safety metrics. Political regime will be binarized into democracy and autocracy for this analysis. Regime will be classified based on the same economic, pollitical, educational, safety, and freedom measures. Decision trees and random forrests will be used to build these models. Classification algorithms will be evaulated through accuracy measures and regression algorithms will be evaluated through the coefficeint of determination. These models will be build out in Python using the Scikit-learn package.\n",
        "\n",
        "# Code Workflow\n",
        "\n",
        "## Package Import, Data Import, and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0b688fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Package Import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e2d16a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Import / Preprocessing\n",
        "df = pd.read_csv('c:\\\\Users\\\\erinb\\\\OneDrive\\\\Documents\\\\Georgetown\\\\DSAN 5000\\\\dsan-5000-project-ebevec\\\\data\\\\01-modified-data\\\\data_clean2.csv')\n",
        "df = df.replace(\",\", \"\", regex = True)\n",
        "df = df.iloc[:,1:]\n",
        "df.columns\n",
        "\n",
        "#To Numeric\n",
        "cols = ['GDP_2019', 'GDP_2020', 'pop_2019', 'pop_2020',\n",
        "       'unemployment_2019', 'unemployment_2020', 'hf_score_2019',\n",
        "       'hf_rank_2019', 'pf_religion_2019', 'pf_expression_2019',\n",
        "       'ef_score_2019', 'pf_ss_2019', 'hf_score_2020', 'hf_rank_2020',\n",
        "       'pf_religion_2020', 'pf_expression_2020', 'ef_score_2020', 'pf_ss_2020', 'Learning.Adjusted.Years.of.School']\n",
        "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Linear Interpolation\n",
        "full_df = df.dropna()\n",
        "\n",
        "# GDP\n",
        "delta = df['GDP_2020'] - df['GDP_2019']\n",
        "delta = delta.mean()\n",
        "\n",
        "df['GDP_2020'] = df['GDP_2020'].fillna(df['GDP_2019'] + delta)\n",
        "df['GDP_2019'] = df['GDP_2019'].fillna(df['GDP_2020'] - delta)\n",
        "df.head()\n",
        "\n",
        "# Population \n",
        "delta2 = full_df['pop_2020'] - full_df['pop_2019']\n",
        "delta2 = delta2.mean()\n",
        "\n",
        "df['pop_2020'] = df['pop_2020'].fillna(df['pop_2019'] + delta)\n",
        "df['pop_2019'] = df['pop_2019'].fillna(df['pop_2020'] - delta)\n",
        "df.head()\n",
        "\n",
        "# Unemployment - Too many NaN for interpolation. Dropping columns. Imputation unreasonable for country-wise comparion.\n",
        "df = df.drop(columns = ['unemployment_2019', 'unemployment_2020'])\n",
        "df = df.drop(columns = ['GDP_2019', 'pop_2019' , 'hf_score_2019', 'hf_rank_2020', 'pf_religion_2019', 'pf_expression_2019', 'ef_score_2019', 'regime_2019', 'pf_ss_2019', 'Year'])\n",
        "df.isna().sum()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9abbd73",
      "metadata": {},
      "source": [
        "## Class Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed817c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class Balance\n",
        "t0 = df[df['regime_2020'] == 'closed autocracy']\n",
        "t1 = df[df['regime_2020'] == 'electoral autocracy']\n",
        "t2 = df[df['regime_2020'] == 'electoral democracy']\n",
        "t3 = df[df['regime_2020'] == 'liberal democracy']\n",
        "\n",
        "t0_num = len(t0)\n",
        "t0_prop = len(t0) / len(df)\n",
        "t1_num = len(t1)\n",
        "t1_prop = len(t1) / len(df)\n",
        "t2_num = len(t2)\n",
        "t2_prop = len(t2) / len(df)\n",
        "t3_num = len(t3)\n",
        "t3_prop = len(t3) / len(df)\n",
        "\n",
        "print('Every Class of Regime')\n",
        "print('Number of points with target= closed autocracy: ', t0_num) \n",
        "print('Proportion: ', t0_prop)\n",
        "print('Number of points with target= electoral autocracy: ', t1_num)\n",
        "print('Proportion: ', t1_prop)\n",
        "print('Number of points with target= electoral democracy: ', t2_num)\n",
        "print('Proportion: ', t2_prop)\n",
        "print('Number of points with target= liberal democracy: ', t3_num)\n",
        "print('Proportion: ', t3_prop)\n",
        "\n",
        "print('Democracy versus Autocracy')\n",
        "print('Number of points with target= autocracy: ', t0_num+t1_num) \n",
        "print('Proportion: ', t0_prop+t1_prop)\n",
        "print('Number of points with target= autocracy: ', t2_num+t3_num)\n",
        "print('Proportion: ', t2_prop+t3_prop)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc064a1",
      "metadata": {},
      "source": [
        "## Baseline Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e9fd84",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def generate_label_data(class_labels, weights,N=10000):\n",
        "    y=random.choices(class_labels, weights = weights, k = N)\n",
        "    print(\"-----GENERATING DATA-----\")\n",
        "    print(\"unique entries:\",Counter(y).keys())  \n",
        "    print(\"count of labels:\",Counter(y).values()) # counts the elements' frequency\n",
        "    print(\"probability of labels:\",np.fromiter(Counter(y).values(), dtype=float)/len(y)) # counts the elements' frequency\n",
        "    return y\n",
        "\n",
        "## RANDOM CLASSIFIER \n",
        "def random_classifier(y_data):\n",
        "    ypred=[];\n",
        "    max_label=np.max(y_data); #print(max_label)\n",
        "    for i in range(0,len(y_data)):\n",
        "        ypred.append(int(np.floor((max_label+1)*np.random.uniform(0,1))))\n",
        "\n",
        "    print(\"-----RANDOM CLASSIFIER-----\")\n",
        "    print(\"count of prediction:\",Counter(ypred).values()) # counts the elements' frequency\n",
        "    print(\"probability of prediction:\",np.fromiter(Counter(ypred).values(), dtype=float)/len(y_data)) # counts the elements' frequency\n",
        "    print(\"accuracy\",accuracy_score(y_data, ypred))\n",
        "    print(\"percision, recall, fscore,\",precision_recall_fscore_support(y_data, ypred))\n",
        "\n",
        "\n",
        "# Based on true class balacne\n",
        "print(\"\\nBINARY CLASS: NON UNIFORM LOAD\")\n",
        "y=generate_label_data([0,1],[0.42,0.58],10000)\n",
        "random_classifier(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24fc7445",
      "metadata": {},
      "source": [
        "## Decision Trees\n",
        "\n",
        "### Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829067fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['regime_2020'] = df['regime_2020'].replace('closed autocracy', 0)\n",
        "df['regime_2020'] = df['regime_2020'].replace('electoral autocracy', 0)\n",
        "df['regime_2020'] = df['regime_2020'].replace('electoral democracy', 1)\n",
        "df['regime_2020'] = df['regime_2020'].replace('liberal democracy', 1)\n",
        "\n",
        "df = df.iloc[:,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229af63e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Matrix\n",
        "\n",
        "corr = df.corr();  #print(corr)\t\t\t\t\t#COMPUTE CORRELATION OF FEATER MATRIX\n",
        "print(corr.shape)\n",
        "sns.set_theme(style=\"white\")\n",
        "f, ax = plt.subplots(figsize=(20, 20))  # Set up the matplotlib figure\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True) \t# Generate a custom diverging colormap\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr,  cmap=cmap, vmin=-1, vmax=1, center=0,\n",
        "        square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9b0ac3b",
      "metadata": {},
      "source": [
        "Train / Test Split - Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08496571",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()\n",
        "X = df.iloc[:,:9]\n",
        "Y = df['regime_2020']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test = train_test_split(X, test_size=0.2, random_state=123)\n",
        "y_train, y_test = train_test_split(Y, test_size=0.2, random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eb2cd6a",
      "metadata": {},
      "source": [
        "Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1b38f74",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, ConfusionMatrixDisplay, recall_score\n",
        "model = tree.DecisionTreeClassifier()\n",
        "model = model.fit(x_train, y_train)\n",
        "\n",
        "yp_train = model.predict(x_train)\n",
        "yp_test = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ec01a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def confusion_plot(y_data, y_pred):\n",
        "    mat = confusion_matrix(y_data, y_pred)\n",
        "    accuracy = accuracy_score(y_data, y_pred)\n",
        "    pos_prec = precision_score(y_data, y_pred)\n",
        "    neg_prec = precision_score(y_data, y_pred, pos_label=0)\n",
        "    pos_recall = precision_score(y_data, y_pred)\n",
        "    neg_recall = precision_score(y_data, y_pred, pos_label=0)\n",
        "    print(\"ACCURACY: \", accuracy)\n",
        "    print(\"NEGATIVE RECALL (Y=0): \", neg_recall)\n",
        "    print(\"NEGATIVE PRECISION (Y=0): \", neg_prec)\n",
        "    print(\"POSITIVE RECALL (Y=1): \", pos_recall)\n",
        "    print(\"POSITIVE PRECISION (Y=1): \" , pos_prec) \n",
        "    print(mat)\n",
        "    disp = ConfusionMatrixDisplay(mat)\n",
        "    disp.plot()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "606fc078",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"------TRAINING------\")\n",
        "confusion_plot(y_train,yp_train)\n",
        "print(\"------TEST------\")\n",
        "confusion_plot(y_test,yp_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30307159",
      "metadata": {},
      "source": [
        "Tree Vizualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b6b092",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn import tree\n",
        "\n",
        "def plot_tree(model,X,Y):\n",
        "    fig = plt.figure(figsize=(25,20))\n",
        "    tree.plot_tree(clf, \n",
        "                   feature_names=X.columns,  \n",
        "                   class_names=True,\n",
        "                   filled=True)\n",
        "    \n",
        "clf = DecisionTreeClassifier(random_state=123)\n",
        "model = clf.fit(X, Y)\n",
        "plot_tree(model, X, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1965c3d4",
      "metadata": {},
      "source": [
        "Hyper-parameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43826ff9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMPLETE THE FOLLOWING CODE TO LOOP OVER POSSIBLE HYPER-PARAMETERS VALUES\n",
        "test_results=[]\n",
        "train_results=[]\n",
        "\n",
        "for num_layer in range(1,20):\n",
        "    model = tree.DecisionTreeClassifier(max_depth=num_layer)\n",
        "    model = model.fit(x_train, y_train)\n",
        "\n",
        "    yp_train=model.predict(x_train)\n",
        "    yp_test=model.predict(x_test)\n",
        "\n",
        "    # print(y_pred.shape)\n",
        "    test_results.append([num_layer,accuracy_score(y_test, yp_test),recall_score(y_test, yp_test,pos_label=0),recall_score(y_test, yp_test,pos_label=1)])\n",
        "    train_results.append([num_layer,accuracy_score(y_train, yp_train),recall_score(y_train, yp_train,pos_label=0),recall_score(y_train, yp_train,pos_label=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84dce758",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_results = pd.DataFrame(train_results)\n",
        "test_results = pd.DataFrame(test_results)\n",
        "\n",
        "plt.plot(train_results[0], train_results[1], '-o')\n",
        "plt.plot(test_results[0], test_results[1], '-o', color = 'firebrick')\n",
        "plt.xlabel(\"Number of layers in decision tree (max_depth)\")\n",
        "plt.ylabel(\"ACCURACY (Y=0): Training (blue) and Test (red)\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_results[0], train_results[2], '-o')\n",
        "plt.plot(test_results[0], test_results[2], '-o', color = 'firebrick')\n",
        "plt.xlabel(\"Number of layers in decision tree (max_depth)\")\n",
        "plt.ylabel(\"RECALL (Y=0): Training (blue) and Test (red)\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_results[0], train_results[3], '-o')\n",
        "plt.plot(test_results[0], test_results[3], '-o', color = 'firebrick')\n",
        "plt.xlabel(\"Number of layers in decision tree (max_depth)\")\n",
        "plt.ylabel(\"RECALL (Y=1): Training (blue) and Test (red)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b80b68b",
      "metadata": {},
      "source": [
        "Optimal Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9e21e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "model = tree.DecisionTreeClassifier(max_depth=1)\n",
        "model = model.fit(x_train, y_train)\n",
        "\n",
        "yp_train=model.predict(x_train)\n",
        "yp_test=model.predict(x_test)\n",
        "\n",
        "print(\"------TRAINING------\")\n",
        "confusion_plot(y_train,yp_train)\n",
        "print(\"------TEST------\")\n",
        "confusion_plot(y_test,yp_test)\n",
        "\n",
        "plot_tree(model,X,Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f7cc33f",
      "metadata": {},
      "source": [
        "### Regression\n",
        "\n",
        "Train / Test Split - Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e6d9253",
      "metadata": {},
      "outputs": [],
      "source": [
        "X2 = df. loc[:, df.columns != 'hf_score_2020']\n",
        "Y2 = df['hf_score_2020']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train2, x_test2 = train_test_split(X2, test_size=0.2, random_state=123)\n",
        "y_train2, y_test2 = train_test_split(Y2, test_size=0.2, random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9eedc1b",
      "metadata": {},
      "source": [
        "Model Fit and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f0cec1b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor  \n",
        "   \n",
        "reg = DecisionTreeRegressor(random_state = 0)  \n",
        "r1 = reg.fit(x_train2, y_train2) \n",
        "print('Coefficient of Determination: ', r1.score(x_test2, y_test2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b25bb46",
      "metadata": {},
      "source": [
        "## Random Forests\n",
        "\n",
        "### Classification\n",
        "\n",
        "Model Fit and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91eee912",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a8fe8b",
      "metadata": {},
      "source": [
        "Hyper-parameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23385d40",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {'n_estimators': randint(50,500),\n",
        "              'max_depth': randint(1,20)}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rand = RandomizedSearchCV(rf, \n",
        "                                 param_distributions = param_dist, \n",
        "                                 n_iter=5, \n",
        "                                 cv=5)\n",
        "\n",
        "rand.fit(x_train, y_train)\n",
        "\n",
        "best_rf = rand.best_estimator_\n",
        "\n",
        "print(rand.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf044a9f",
      "metadata": {},
      "source": [
        "Optimal Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e75f44",
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(max_depth = 2, n_estimators=432, oob_score=True)\n",
        "rf.fit(x_train, y_train)\n",
        "print(rf.oob_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "542a227b",
      "metadata": {},
      "source": [
        "### Regression\n",
        "\n",
        "Model Fit and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d238aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf2 = RandomForestRegressor(oob_score=True)\n",
        "rf2.fit(x_train2, y_train2)\n",
        "\n",
        "y_pred2 = rf2.predict(x_test2)\n",
        "\n",
        "print('Score:', rf2.oob_score_)\n",
        "print('Feature Importances: ', rf2.feature_importances_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "608f400a",
      "metadata": {},
      "source": [
        "Hyperparameter Fine Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25979388",
      "metadata": {},
      "outputs": [],
      "source": [
        "rand = RandomizedSearchCV(rf2, \n",
        "                                 param_distributions = param_dist, \n",
        "                                 n_iter=5, \n",
        "                                 cv=5)\n",
        "\n",
        "rand.fit(x_train, y_train)\n",
        "\n",
        "best_rf = rand.best_estimator_\n",
        "\n",
        "print(rand.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7880c822",
      "metadata": {},
      "source": [
        "Optimal Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c10d102",
      "metadata": {},
      "outputs": [],
      "source": [
        "rf2 = RandomForestRegressor(max_depth = 8, n_estimators = 196, oob_score=True)\n",
        "rf2.fit(x_train2, y_train2)\n",
        "\n",
        "y_pred2 = rf2.predict(x_test2)\n",
        "\n",
        "print('Score:', rf2.oob_score_)\n",
        "print('Feature Importances: ', rf2.feature_importances_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e81a2d19",
      "metadata": {},
      "source": [
        "# Final Results\n",
        "\n",
        "The decision tree for classification returned an initial accuracy of 85%. After hyperparameter fine tuning, the accuracy was 92%.\n",
        "The decision tree for regression returned a coefficient of determination of 0.97.\n",
        "The random forest for classification returned an initial OOB score of 0.88. After fine tuning using a Randomized Search CV, the model accuracy was the same indicating that the initial run was the optimal model.\n",
        "The random forest for regression retruned an initial OOB Score of 0.97. After fine tuning using a Randomized Search CV, the model accuracy was the same indicating that the initial run was the optimal model.\n",
        "Additional data could improve model performance for both models.\n",
        "\n",
        "# Conclusions\n",
        "\n",
        "This analysis developed predictive models for political regime and human freedom score using decision trees and random forests. First, the classifier algorithms for political regime will be discussed. This analysis involved a binary classification of autocracy (y=0) and democracy(y=1). Initially, a baseline classifier was generated. This classifier was based upon the actual class distribution in which 42% of nations were autocratic and 58% of nations were democratic. This model returned an accuracy of 0.5, meaning that the random classifier predicts class accurately 50% of the time. This model will be used to compare and evalulate the random forests and decision trees. Next, a decision tree was generated and fine tuned. The final accuracy of this model was 0.92, which is higher than the random classifier. Thus, 92% of the time, the decision tree can appropriately identify political regime of a nation based on their economic, social, political, and freedom indicators. A random forest was then used to model the same relationship. The random forest had an accuracy of 0.88 which was higher than the baseline model for classification. So, 92% of the time, the random forest can appropriately identify political regime of a nation based on their economic, social, political, and freedom indicators. This was less accurate than the decision tree, although the model may be more robust as it is insensitive to overfitting.\n",
        "\n",
        "Next, the regression algorithms for human freedom score will be evaluated. A decision tree was implemented to build the regression model for the country-wise dataset. The coefficient of determination from this regression model was 0.97, which indicates that the model is consistent in predicting relative to the observed outcomes for human freedom score. A random forest was then used to model the same relationship. The accuracy of the random forest was 0.97. This number indicates high performance of the random forest in predicting human freedom score based on the economic, social, and political, indicators. Both regression models had high performance for this outcome.\n",
        "\n",
        "These models effectively developed a rule based system to predict political regime and human freedom based on the indicators in the dataset. This can be used to predict future freedom or changes in regime in accordance with geopolitical change. For example, we can model how the freedom of some country will change given their GDP increases by some amount using the classification model. Or, we can predict future changes in regime if the population changes significantly using the regression model. These models could be used by policy makers, researchers, or military professionals to understand the complex and everchagning geopolitical dynamics of our world.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
